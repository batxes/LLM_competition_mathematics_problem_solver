{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86ebbeb-c070-45d4-99ef-de33b53d447d",
   "metadata": {
    "id": "c86ebbeb-c070-45d4-99ef-de33b53d447d"
   },
   "source": [
    "### Install and Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "v5gOKYkO3sI2",
   "metadata": {
    "id": "v5gOKYkO3sI2"
   },
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "! pip install -qU langchain-openai langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7a0c7bd-512d-4e5b-ab43-1bc3b8c97fd4",
   "metadata": {
    "id": "f7a0c7bd-512d-4e5b-ab43-1bc3b8c97fd4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90E3nLng33Ct",
   "metadata": {
    "id": "90E3nLng33Ct"
   },
   "source": [
    "### Set up OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "iPETn3V83rc3",
   "metadata": {
    "id": "iPETn3V83rc3"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def _get_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_get_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ad035-2c1a-4e31-93b4-58793d219bc9",
   "metadata": {
    "id": "2e4ad035-2c1a-4e31-93b4-58793d219bc9"
   },
   "source": [
    "### Application Design\n",
    "\n",
    "Some helper functions to set up this app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "MD8YN6JYCT0J",
   "metadata": {
    "id": "MD8YN6JYCT0J"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0, max_tokens=1500)\n",
    "#llm = OpenAI(model_name=\"davinci-002\", temperature=0, max_tokens=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a0ddd307-b41c-4aeb-81b1-4be77647e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRY\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_path = 'Alibaba-NLP/gte-large-en-v1.5'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModel.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4ddb3-8724-4a86-a153-5ed30d07bd56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "tuOo27j1SDl3",
   "metadata": {
    "id": "tuOo27j1SDl3"
   },
   "source": [
    "#### Function to query the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "Ofi_fPrGPHLd",
   "metadata": {
    "id": "Ofi_fPrGPHLd"
   },
   "outputs": [],
   "source": [
    "def get_answer(question):\n",
    "    prompt = f\"\"\"Please solve the following high school math problem step by step. Explain your reasoning clearly and provide the final answer.\n",
    "\n",
    "{question}\n",
    "\n",
    "Step-by-step solution and final answer:\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    print (response)\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f6389032-ca12-4ae3-8fa8-4880f56079f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRY\n",
    "\n",
    "def get_answer(question):\n",
    "    prompt = f\"\"\"Please solve the following high school math problem step by step. Explain your reasoning clearly and provide the final answer.\n",
    "\n",
    "{question}\n",
    "\n",
    "Step-by-step solution and final answer:\"\"\"\n",
    "    # Tokenize the input texts\n",
    "    batch_dict = tokenizer(prompt, max_length=8192, padding=True, truncation=True, return_tensors='pt')\n",
    "    # Generate a response\n",
    "    outputs = model(**batch_dict)\n",
    "    #with torch.no_grad():\n",
    "    #    outputs = model.generate(inputs[\"input_ids\"], max_length=50, num_return_sequences=1)\n",
    "\n",
    "    embeddings = outputs.last_hidden_state[:, 0]\n",
    "    \n",
    "    # Decode the response\n",
    "    response = tokenizer.decode(embeddings[0], skip_special_tokens=True)\n",
    "\n",
    "    print (response)\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9da548-e62f-485b-949a-b9d488d07e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa86d6-9676-4063-9182-b40540e76a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sQoV28mwPMcY",
   "metadata": {
    "id": "sQoV28mwPMcY"
   },
   "source": [
    "#### Function to Extract Answer with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "35CWYSJgPVNe",
   "metadata": {
    "id": "35CWYSJgPVNe"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_numerical_answer(text):\n",
    "    # Look for patterns like \"Final answer: X\" or \"The answer is X\" at the end of the text\n",
    "    match = re.search(r'(?:final answer|the answer is)[:\\s]*([+-]?\\d*\\.?\\d+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    else:\n",
    "        # If no clear final answer, look for the last number in the text\n",
    "        numbers = re.findall(r'[+-]?\\d*\\.?\\d+', text)\n",
    "        return float(numbers[-1]) if numbers else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qeLhlhiTPm4I",
   "metadata": {
    "id": "qeLhlhiTPm4I"
   },
   "source": [
    "#### Function to Prepare Dataset and Get Answers with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca849b-d271-4a9e-bc6e-1ab47af1bffe",
   "metadata": {
    "id": "qeLhlhiTPm4I"
   },
   "source": [
    "We will use a pool executor to make it faster (`max_workers=6` controls how many concurrent queries we send to OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "17e8befe-4f9e-4342-8945-54b96a4c1678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "pool = ThreadPoolExecutor(max_workers=6)\n",
    "\n",
    "def map_progress(pool, seq, f):\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(seq)) as progress:\n",
    "        futures = []\n",
    "\n",
    "        for el in seq:\n",
    "            future = pool.submit(f, el)\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d5c12-6c58-4d45-b8f5-299f84c1fbe3",
   "metadata": {},
   "source": [
    "Now we create a function for processing each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e620d41d-8298-47f1-9a14-a257727157f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    problem_id = row['problem_id']\n",
    "    problem_text = row['problem_text']\n",
    "\n",
    "    llm_reasoning = get_answer(problem_text)\n",
    "\n",
    "    numerical_answer = extract_numerical_answer(llm_reasoning)\n",
    "\n",
    "    return {\n",
    "        'problem_id': problem_id,\n",
    "        'problem_text': problem_text,\n",
    "        'llm_reasoning': llm_reasoning,\n",
    "        'answer': numerical_answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb90eaf-82aa-422a-85de-dd3769ac9723",
   "metadata": {},
   "source": [
    "At this point, let's load the train data - so we can use it for evaluation our solution offline (without submitting to Kaggle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "DimbAMWpP6Dj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DimbAMWpP6Dj",
    "outputId": "693e5a26-657f-4edc-a693-57d8e16dcfe2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>problem_text</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2374</td>\n",
       "      <td>Find the value of the expression $\\dfrac{17}{5...</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4723</td>\n",
       "      <td>In a company of 30 people, 25 use the social n...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7135</td>\n",
       "      <td>The number of road traffic accidents (RTAs) in...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5814</td>\n",
       "      <td>Find the value of the expression $\\dfrac{2\\str...</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237</td>\n",
       "      <td>A traveler from Moscow wants to visit four cit...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem_id                                       problem_text answer\n",
       "0        2374  Find the value of the expression $\\dfrac{17}{5...    1.6\n",
       "1        4723  In a company of 30 people, 25 use the social n...     24\n",
       "2        7135  The number of road traffic accidents (RTAs) in...     32\n",
       "3        5814  Find the value of the expression $\\dfrac{2\\str...    256\n",
       "4        9237  A traveler from Moscow wants to visit four cit...     53"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a694391e-a890-4507-816c-5cf118e90bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPooling(last_hidden_state=tensor([[[-0.3443, -0.0185, -0.8017,  ..., -1.0034,  0.2730, -0.2280],\n",
      "         [-0.7687, -0.4095, -1.1336,  ..., -1.0025,  0.5432, -0.2095],\n",
      "         [-0.5798, -0.2167, -1.5978,  ..., -0.9039,  1.0024, -0.4906],\n",
      "         ...,\n",
      "         [-0.4398, -0.5099, -1.4643,  ..., -0.9591,  0.6514, -0.5629],\n",
      "         [-0.5937, -0.5508, -0.9927,  ..., -0.9767,  0.4471, -0.0905],\n",
      "         [-0.4997,  0.0255, -0.7478,  ..., -1.0019,  0.3506, -0.4382]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=None, hidden_states=None, attentions=None)\n",
      "tensor([[-0.3443, -0.0185, -0.8017,  ..., -1.0034,  0.2730, -0.2280]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([-0.3443, -0.0185, -0.8017,  ..., -1.0034,  0.2730, -0.2280],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': 'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m rows \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39mhead()\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m process_row(rows[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[144], line 5\u001b[0m, in \u001b[0;36mprocess_row\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      2\u001b[0m problem_id \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m problem_text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m llm_reasoning \u001b[38;5;241m=\u001b[39m get_answer(problem_text)\n\u001b[1;32m      7\u001b[0m numerical_answer \u001b[38;5;241m=\u001b[39m extract_numerical_answer(llm_reasoning)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem_id\u001b[39m\u001b[38;5;124m'\u001b[39m: problem_id,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem_text\u001b[39m\u001b[38;5;124m'\u001b[39m: problem_text,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllm_reasoning\u001b[39m\u001b[38;5;124m'\u001b[39m: llm_reasoning,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m: numerical_answer\n\u001b[1;32m     14\u001b[0m }\n",
      "Cell \u001b[0;32mIn[141], line 21\u001b[0m, in \u001b[0;36mget_answer\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m (embeddings[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Decode the response\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(embeddings, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m (response)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4034\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   4031\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   4032\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 4034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[1;32m   4035\u001b[0m     token_ids\u001b[38;5;241m=\u001b[39mtoken_ids,\n\u001b[1;32m   4036\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[1;32m   4037\u001b[0m     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[1;32m   4038\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4039\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:651\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    650\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[0;32m--> 651\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mdecode(token_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens)\n\u001b[1;32m    653\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    654\u001b[0m     clean_up_tokenization_spaces\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[1;32m    657\u001b[0m )\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'ids': 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "rows = df_train.head().to_dict(orient='records')\n",
    "process_row(rows[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3da223-3af9-4703-a239-b103d4e5575e",
   "metadata": {},
   "source": [
    "This is how we combine the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67df87cf-e27d-45bc-94fa-16d1e543b086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef74f636ccff41c381d6a95286c77842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>problem_text</th>\n",
       "      <th>llm_reasoning</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2374</td>\n",
       "      <td>Find the value of the expression $\\dfrac{17}{5...</td>\n",
       "      <td>To solve this problem, we will first simplify ...</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4723</td>\n",
       "      <td>In a company of 30 people, 25 use the social n...</td>\n",
       "      <td>1) In this company, there will be 10 people wh...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7135</td>\n",
       "      <td>The number of road traffic accidents (RTAs) in...</td>\n",
       "      <td>Step 1: Let x be the number of RTAs in the win...</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5814</td>\n",
       "      <td>Find the value of the expression $\\dfrac{2\\str...</td>\n",
       "      <td>To solve this problem, we will use the propert...</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237</td>\n",
       "      <td>A traveler from Moscow wants to visit four cit...</td>\n",
       "      <td>To visit all four cities and spend less than 5...</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem_id                                       problem_text  \\\n",
       "0        2374  Find the value of the expression $\\dfrac{17}{5...   \n",
       "1        4723  In a company of 30 people, 25 use the social n...   \n",
       "2        7135  The number of road traffic accidents (RTAs) in...   \n",
       "3        5814  Find the value of the expression $\\dfrac{2\\str...   \n",
       "4        9237  A traveler from Moscow wants to visit four cit...   \n",
       "\n",
       "                                       llm_reasoning  answer  \n",
       "0  To solve this problem, we will first simplify ...    17.0  \n",
       "1  1) In this company, there will be 10 people wh...    24.0  \n",
       "2  Step 1: Let x be the number of RTAs in the win...    32.0  \n",
       "3  To solve this problem, we will use the propert...   256.0  \n",
       "4  To visit all four cities and spend less than 5...    46.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = map_progress(pool, rows, process_row)\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b5ae96e-31dc-49f3-a1eb-39497d235cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>problem_text</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2374</td>\n",
       "      <td>Find the value of the expression $\\dfrac{17}{5...</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4723</td>\n",
       "      <td>In a company of 30 people, 25 use the social n...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7135</td>\n",
       "      <td>The number of road traffic accidents (RTAs) in...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5814</td>\n",
       "      <td>Find the value of the expression $\\dfrac{2\\str...</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237</td>\n",
       "      <td>A traveler from Moscow wants to visit four cit...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem_id                                       problem_text answer\n",
       "0        2374  Find the value of the expression $\\dfrac{17}{5...    1.6\n",
       "1        4723  In a company of 30 people, 25 use the social n...     24\n",
       "2        7135  The number of road traffic accidents (RTAs) in...     32\n",
       "3        5814  Find the value of the expression $\\dfrac{2\\str...    256\n",
       "4        9237  A traveler from Moscow wants to visit four cit...     53"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91fdfb6-ee87-401f-bdef-f9628d7fe4f0",
   "metadata": {},
   "source": [
    "Let's evaluate the answer on these 5 examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff311f15-0302-48cb-8569-af52f8b664a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scorer import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "491bce46-7d0c-49fd-a1cd-5d2cb85d4f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(df_train.head(), df_results, 'problem_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa342dc1-45b6-419c-91a2-dc6fb3c59490",
   "metadata": {},
   "source": [
    "So, 3/5 correct answers. Note that the results are not always deterministic, so the quality may vary.\n",
    "\n",
    "Let's now put this together in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gVrSUBPfPrzk",
   "metadata": {
    "id": "gVrSUBPfPrzk"
   },
   "outputs": [],
   "source": [
    "def prepare_prompts_and_get_answers(df):\n",
    "    rows = df.to_dict(orient='records')\n",
    "    results = map_progress(pool, rows, process_row)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8AnFw9YaSjyJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8AnFw9YaSjyJ",
    "outputId": "31fa3be5-98fb-499f-d2cb-0b35f814f1e3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22a3eae90f04b2194d63f334be73062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>problem_text</th>\n",
       "      <th>llm_reasoning</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2374</td>\n",
       "      <td>Find the value of the expression $\\dfrac{17}{5...</td>\n",
       "      <td>To solve this problem, we will first simplify ...</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4723</td>\n",
       "      <td>In a company of 30 people, 25 use the social n...</td>\n",
       "      <td>1) In this company, there will be 10 people wh...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7135</td>\n",
       "      <td>The number of road traffic accidents (RTAs) in...</td>\n",
       "      <td>Step 1: Let x be the number of RTAs in the win...</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5814</td>\n",
       "      <td>Find the value of the expression $\\dfrac{2\\str...</td>\n",
       "      <td>To solve this problem, we will use the propert...</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237</td>\n",
       "      <td>A traveler from Moscow wants to visit four cit...</td>\n",
       "      <td>To visit all four cities and spend less than 5...</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem_id                                       problem_text  \\\n",
       "0        2374  Find the value of the expression $\\dfrac{17}{5...   \n",
       "1        4723  In a company of 30 people, 25 use the social n...   \n",
       "2        7135  The number of road traffic accidents (RTAs) in...   \n",
       "3        5814  Find the value of the expression $\\dfrac{2\\str...   \n",
       "4        9237  A traveler from Moscow wants to visit four cit...   \n",
       "\n",
       "                                       llm_reasoning  answer  \n",
       "0  To solve this problem, we will first simplify ...    17.0  \n",
       "1  1) In this company, there will be 10 people wh...    24.0  \n",
       "2  Step 1: Let x be the number of RTAs in the win...    32.0  \n",
       "3  To solve this problem, we will use the propert...   256.0  \n",
       "4  To visit all four cities and spend less than 5...    46.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_results = prepare_prompts_and_get_answers(df_train)\n",
    "df_train_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8983d04-d11c-4052-bcb4-09c59b5d77f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(df_train, df_train_results, 'problem_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0f207-be0d-4a6d-aafd-0e1b3d132279",
   "metadata": {},
   "source": [
    "So in our tests, the solution is 42% correct. Let's prepare a test submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6e020-0fdf-413c-9779-20ef99725ee3",
   "metadata": {},
   "source": [
    "## Preparing the test submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "WV8oslsxRUhX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WV8oslsxRUhX",
    "outputId": "e363b602-9bd8-44b1-a8f6-ab2df1b4bbbb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d041ed288cec49c49440a0b32cd3578e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "df_test_results = prepare_prompts_and_get_answers(df_test)\n",
    "\n",
    "submission = df_test_results[['problem_id', 'answer']]\n",
    "submission.to_csv('starter_notebook_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d61c39-e01c-4192-9467-5820602e6ee7",
   "metadata": {},
   "source": [
    "Now submit it to Kaggle. This solution gets 50% on the public leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6H16KMkESocU",
   "metadata": {
    "id": "6H16KMkESocU"
   },
   "source": [
    "### **Conclusion and Tips for Success**\n",
    "\n",
    "Congratulations on getting started with this competition! As you proceed, keep these valuable insights in mind:\n",
    "\n",
    "* **Understanding Langchain**\n",
    "\n",
    "  Imagine foundation models (like ChatGPT, Claude, etc.) as ingredients, and companies ([OpenAI](https://platform.openai.com/playground/chat), [Anthropic](https://console.anthropic.com/workbench), [Cohere](https://cohere.com/) as vendors. In this analogy, [Langchain](https://python.langchain.com/v0.2/docs/introduction/) is your kitchen - a place to combine these ingredients from different vendors into a finished dish (your project). While this starter uses Langchain, explore other \"kitchens\" like [LlamaIndex](https://www.llamaindex.ai/) or [FlowiseAI](https://docs.flowiseai.com/) to find the best tools for your specific needs.\n",
    "  \n",
    "* **Model Selection**\n",
    "\n",
    "  The solution provided uses GPT-3.5-turbo-instruct, a model fine-tuned for following instructions. This choice is deliberate, given the question-answer format of the dataset. When selecting models, consider their strengths in relation to your task.\n",
    "\n",
    "* **Evaluate Model Performance**\n",
    "\n",
    "  Don't just pick a model blindly. Research LLM leaderboards (like the [MTEB leaderboard](https://huggingface.co/spaces/mteb/leaderboard)) to understand how different models perform across various metrics. This information can guide your model selection process.\n",
    "\n",
    "* **Explore Paid Options**\n",
    "\n",
    "  While the baseline solution uses a free model, don't limit yourself. Paid models like GPT-4 often outperform free alternatives. Consider the potential return on investment when deciding whether to use paid services.\n",
    "\n",
    "* **Master the Art of Prompting**\n",
    "\n",
    "  You're the chef in this AI kitchen. Experiment with different prompts to guide the LLM's responses. Be specific in your instructions, and think creatively about how to elicit the best possible answers from the model. For example, *You are a world-class expert at solving High school olympiad math questions...*\n",
    "\n",
    "* **Iterate and Improve**\n",
    "\n",
    "  Use the baseline as a starting point, not an end goal. Continuously refine your approach, trying different models, prompts, and post-processing techniques to improve your results.\n",
    "\n",
    "* **Stay Curious and Adaptive**\n",
    "\n",
    "  The field of AI is rapidly evolving. Stay open to new models, techniques, and tools that emerge during the competition. Your ability to adapt and incorporate new ideas could be the key to success. For example: Recently, Anthropic released a new model that is said to be better than GPT-4o at reasoning tasks.\n",
    "\n",
    "Remember, this competition is not just about reaching a high score â€“ it's an opportunity to deepen your understanding of LLMs and develop practical skills in AI application development. Enjoy the process of learning and discovery as you work towards your solution. Good luck!\n",
    "\n",
    "Okay, it's time to cook, chef!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea28c5-1042-4b98-9219-498ec56f597f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
